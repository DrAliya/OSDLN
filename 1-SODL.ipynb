{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d6539550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 494020 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        181       5450     0   \n",
       "1         0           tcp    http   SF        239        486     0   \n",
       "2         0           tcp    http   SF        235       1337     0   \n",
       "3         0           tcp    http   SF        219       1337     0   \n",
       "4         0           tcp    http   SF        217       2032     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  dst_host_srv_rerror_rate outcome  \n",
       "0               0       0    0                       0.0  normal  \n",
       "1               0       0    0                       0.0  normal  \n",
       "2               0       0    0                       0.0  normal  \n",
       "3               0       0    0                       0.0  normal  \n",
       "4               0       0    0                       0.0  normal  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in KDD99 Data SetÂ¶\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('kddcup1.csv')\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df1)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "\n",
    "df1.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df1.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'outcome'\n",
    "]\n",
    "\n",
    "# display 5 rows\n",
    "df1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "78a1e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(df):\n",
    "    print()\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f4611c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "494020 rows\n",
      "** duration:2495 (0%)\n",
      "** protocol_type:[icmp:57.41%,tcp:38.47%,udp:4.12%]\n",
      "** service:[ecr_i:56.96%,private:22.45%,http:13.01%,smtp:1.97%,other:1.46%,domain_u:1.19%,ftp_data:0.96%,eco_i:0.33%,ftp:0.16%,finger:0.14%,urp_i:0.11%,telnet:0.1%,ntp_u:0.08%,auth:0.07%,pop_3:0.04%,time:0.03%,csnet_ns:0.03%,remote_job:0.02%,gopher:0.02%,imap4:0.02%,discard:0.02%,domain:0.02%,iso_tsap:0.02%,systat:0.02%,shell:0.02%,echo:0.02%,rje:0.02%,whois:0.02%,sql_net:0.02%,printer:0.02%,nntp:0.02%,courier:0.02%,sunrpc:0.02%,netbios_ssn:0.02%,mtp:0.02%,vmnet:0.02%,uucp_path:0.02%,uucp:0.02%,klogin:0.02%,bgp:0.02%,ssh:0.02%,supdup:0.02%,nnsp:0.02%,login:0.02%,hostnames:0.02%,efs:0.02%,daytime:0.02%,link:0.02%,netbios_ns:0.02%,pop_2:0.02%,ldap:0.02%,netbios_dgm:0.02%,exec:0.02%,http_443:0.02%,kshell:0.02%,name:0.02%,ctf:0.02%,netstat:0.02%,Z39_50:0.02%,IRC:0.01%,urh_i:0.0%,X11:0.0%,tim_i:0.0%,pm_dump:0.0%,tftp_u:0.0%,red_i:0.0%]\n",
      "** flag:[SF:76.6%,S0:17.61%,REJ:5.44%,RSTR:0.18%,RSTO:0.12%,SH:0.02%,S1:0.01%,S2:0.0%,RSTOS0:0.0%,S3:0.0%,OTH:0.0%]\n",
      "** src_bytes:3300 (0%)\n",
      "** dst_bytes:10725 (2%)\n",
      "** land:[0:100.0%,1:0.0%]\n",
      "** wrong_fragment:[0:99.75%,3:0.2%,1:0.05%]\n",
      "** urgent:[0:100.0%,1:0.0%,2:0.0%,3:0.0%]\n",
      "** hot:[0:99.35%,2:0.44%,28:0.06%,1:0.05%,4:0.02%,6:0.02%,5:0.01%,3:0.01%,14:0.01%,30:0.01%,22:0.01%,19:0.0%,24:0.0%,18:0.0%,20:0.0%,7:0.0%,17:0.0%,12:0.0%,16:0.0%,10:0.0%,15:0.0%,9:0.0%]\n",
      "** dst_host_srv_rerror_rate:101 (0%)\n",
      "** outcome:[smurf:56.84%,neptune:21.7%,normal:19.69%,back:0.45%,satan:0.32%,ipsweep:0.25%,portsweep:0.21%,warezclient:0.21%,teardrop:0.2%,pod:0.05%,nmap:0.05%,guess_passwd:0.01%,buffer_overflow:0.01%,land:0.0%,warezmaster:0.0%,imap:0.0%,rootkit:0.0%,loadmodule:0.0%,ftp_write:0.0%,multihop:0.0%,phf:0.0%,perl:0.0%,spy:0.0%]\n"
     ]
    }
   ],
   "source": [
    "# Analyze KDD-99\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "\n",
    "analyze(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e4093592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df1.drop('protocol_type', axis=1)\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "    \n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a7e83011",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_numeric_zscore(df1, 'duration')\n",
    "encode_numeric_zscore(df1, 'src_bytes')\n",
    "encode_numeric_zscore(df1, 'dst_bytes')\n",
    "encode_numeric_zscore(df1, 'wrong_fragment')\n",
    "encode_numeric_zscore(df1, 'urgent')\n",
    "encode_numeric_zscore(df1, 'hot')\n",
    "encode_numeric_zscore(df1, 'dst_host_srv_rerror_rate')\n",
    "encode_text_dummy(df1, 'protocol_type')\n",
    "encode_text_dummy(df1, 'service')\n",
    "encode_text_dummy(df1, 'flag')\n",
    "encode_text_dummy(df1, 'land')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "aa9d2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy - Classification\n",
    "x_columns1 = df1.columns.drop('outcome')\n",
    "x1 = df1[x_columns1].values\n",
    "dummies1 = pd.get_dummies(df1['outcome']) # Classification\n",
    "outcomes1 = dummies1.columns\n",
    "num_classes1 = len(outcomes1)\n",
    "y1 = dummies1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "40ca635b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "back                 2203\n",
       "buffer_overflow        30\n",
       "ftp_write               8\n",
       "guess_passwd           53\n",
       "imap                   12\n",
       "ipsweep              1247\n",
       "land                   21\n",
       "loadmodule              9\n",
       "multihop                7\n",
       "neptune            107201\n",
       "nmap                  231\n",
       "normal              97277\n",
       "perl                    3\n",
       "phf                     4\n",
       "pod                   264\n",
       "portsweep            1040\n",
       "rootkit                10\n",
       "satan                1589\n",
       "smurf              280790\n",
       "spy                     2\n",
       "teardrop              979\n",
       "warezclient          1020\n",
       "warezmaster            20\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby('outcome')['outcome'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b022b9",
   "metadata": {},
   "source": [
    "# Defining a neural network model using Keras, \n",
    "# a high-level neural networks API that runs on top of TensorFlow or other backend engines. \n",
    "# The model is a feedforward neural network with multiple layers. \n",
    "# Here's a brief explanation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f8f7842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(\n",
    "    x1, y1, test_size=0.25, random_state=42)\n",
    "\n",
    "from sklearn import metrics\n",
    "from IPython.display import display, HTML \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x1.shape[1], activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(x1.shape[1], activation='linear'))(original_branch) \n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "################ SAVING THE LAST OUTPUT LAYER ##################\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Assuming you have already defined your original model as 'model'\n",
    "# and it looks like the one in your previous code\n",
    "\n",
    "# Create a new model with just the last layer\n",
    "last_layer = Dense(x1.shape[1], name='output_layer')(model.layers[-1].output)\n",
    "output_model = Model(inputs=model.input, outputs=last_layer)\n",
    "\n",
    "# Save the last layer model to a file\n",
    "output_model.save('last_layer_model.h5')\n",
    "\n",
    "\n",
    "################## ATTENTION WEIGHTS ########################\n",
    "\n",
    "attention_weights = AttentionLayer()(original_branch)\n",
    "\n",
    "\n",
    "# Merge the attention weights with the new input features\n",
    "merged_input = Concatenate()([attention_weights, input_new])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da710906",
   "metadata": {},
   "source": [
    "1. `Sequential()`: This line initializes a sequential neural network model, \n",
    "    which means you can add layers sequentially one after another.\n",
    "\n",
    "2. `model.add(Dense(25, input_dim=x1.shape[1], activation='relu'))`: \n",
    "    This line adds the first layer to the model. \n",
    "    It's a fully connected (Dense) layer with 25 units/neurons, and it takes an input of shape `x1.shape[1]`. \n",
    "    The activation function used here is ReLU (Rectified Linear Unit).\n",
    "\n",
    "3. `model.add(Dense(3, activation='relu'))`: \n",
    "    This adds a second fully connected layer with 3 units and ReLU activation. \n",
    "    This layer reduces the output dimensions from the previous layer to 3 units.\n",
    "\n",
    "4. `model.add(Dense(25, activation='relu'))`: \n",
    "    Another fully connected layer with 25 units and ReLU activation is added. \n",
    "    This increases the output dimensions back to 25 units.\n",
    "\n",
    "5. `model.add(Dense(x1.shape[1]))`: \n",
    "    The final layer in your model is another fully connected layer \n",
    "    with the same number of units as the input dimensions (`x1.shape[1]`). \n",
    "    This layer typically serves as the output layer in autoencoders or similar models, \n",
    "    where we're trying to reconstruct the input.\n",
    "\n",
    "It's important to note that the architecture we've provided does not have an explicit activation \n",
    "function for the output layer. But, we might want to add an appropriate activation function \n",
    "(e.g., sigmoid for binary classification, softmax for multi-class classification) to the output layer, \n",
    "especially if you're using this network for classification tasks.\n",
    "\n",
    "Also, ensure that we compile the model with an appropriate loss function, optimizer, and evaluation metrics \n",
    "before training it on your data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd13d6",
   "metadata": {},
   "source": [
    "# SAVE THE LAST LAYER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8342313d",
   "metadata": {},
   "source": [
    "If we want to save the weights and architecture of just the last layer of your Keras model, \n",
    "we can create a new model that includes only that layer and then save it separately. \n",
    "\n",
    "In this code:\n",
    "\n",
    "1. We create a new model (`output_model`) that takes the input from your original model \n",
    "and has only the last dense layer (`Dense(x1.shape[1])`). We name this last layer 'output_layer'.\n",
    "\n",
    "2. The `Model` constructor is used to create this new model with the specified input and output layers.\n",
    "\n",
    "3. Finally, we save the `output_model` to a file named 'last_layer_model.h5' using the `save` method. \n",
    "This file will contain the weights and architecture of just the last layer, \n",
    "allowing you to load and use it separately in the future.\n",
    "\n",
    "After saving, we can load this saved last layer model using \n",
    "`tensorflow.keras.models.load_model('last_layer_model.h5')` \n",
    "if we need to use it in a different script or at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5fc1bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the output into a Pandas dataframe\n",
    "pd1 = pd.DataFrame(x1, columns=['output_neuron_{}'.format(i+1) for i in range(x1.shape[1])])\n",
    "\n",
    "# Save the output to a CSV file\n",
    "pd1.to_csv('dense_output1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5878e702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11579/11579 - 9s - loss: 0.2601 - val_loss: 0.0950 - 9s/epoch - 775us/step\n",
      "Epoch 2/1000\n",
      "11579/11579 - 8s - loss: 0.0824 - val_loss: 0.0739 - 8s/epoch - 728us/step\n",
      "Epoch 3/1000\n",
      "11579/11579 - 8s - loss: 0.0710 - val_loss: 0.0548 - 8s/epoch - 727us/step\n",
      "Epoch 4/1000\n",
      "11579/11579 - 8s - loss: 0.0564 - val_loss: 0.0557 - 8s/epoch - 730us/step\n",
      "Epoch 5/1000\n",
      "11579/11579 - 8s - loss: 0.0518 - val_loss: 0.0476 - 8s/epoch - 726us/step\n",
      "Epoch 6/1000\n",
      "11579/11579 - 8s - loss: 0.0658 - val_loss: 0.0466 - 8s/epoch - 730us/step\n",
      "Epoch 7/1000\n",
      "11579/11579 - 8s - loss: 0.0504 - val_loss: 0.0459 - 8s/epoch - 722us/step\n",
      "Epoch 8/1000\n",
      "11579/11579 - 8s - loss: 0.0452 - val_loss: 0.0432 - 8s/epoch - 730us/step\n",
      "Epoch 9/1000\n",
      "11579/11579 - 8s - loss: 0.0499 - val_loss: 0.0455 - 8s/epoch - 722us/step\n",
      "Epoch 10/1000\n",
      "11579/11579 - 8s - loss: 0.0435 - val_loss: 0.0456 - 8s/epoch - 728us/step\n",
      "Epoch 11/1000\n",
      "11579/11579 - 8s - loss: 0.0468 - val_loss: 0.0422 - 8s/epoch - 720us/step\n",
      "Epoch 12/1000\n",
      "11579/11579 - 8s - loss: 0.0480 - val_loss: 0.0412 - 8s/epoch - 732us/step\n",
      "Epoch 13/1000\n",
      "11579/11579 - 8s - loss: 0.0512 - val_loss: 0.0421 - 8s/epoch - 723us/step\n",
      "Epoch 14/1000\n",
      "11579/11579 - 8s - loss: 0.0448 - val_loss: 0.0416 - 8s/epoch - 731us/step\n",
      "Epoch 15/1000\n",
      "11579/11579 - 8s - loss: 0.0483 - val_loss: 0.0399 - 8s/epoch - 724us/step\n",
      "Epoch 16/1000\n",
      "11579/11579 - 8s - loss: 0.0428 - val_loss: 0.0399 - 8s/epoch - 731us/step\n",
      "Epoch 17/1000\n",
      "11579/11579 - 8s - loss: 0.0424 - val_loss: 0.0422 - 8s/epoch - 723us/step\n",
      "Epoch 18/1000\n",
      "11579/11579 - 8s - loss: 0.0407 - val_loss: 0.0403 - 8s/epoch - 733us/step\n",
      "Epoch 19/1000\n",
      "11579/11579 - 8s - loss: 0.0414 - val_loss: 0.0401 - 8s/epoch - 723us/step\n",
      "Epoch 20/1000\n",
      "11579/11579 - 8s - loss: 0.0395 - val_loss: 0.0401 - 8s/epoch - 729us/step\n",
      "Epoch 20: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e80060490>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x1.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x1.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, input_dim=x1.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.add(Dense(y1.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model.fit(x1_train,y1_train,validation_data=(x1_test,y1_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dcefe424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3860/3860 [==============================] - 2s 419us/step\n",
      "Validation score: 0.9905428930002834\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Measure accuracy\n",
    "pred = model.predict(x1_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_eval = np.argmax(y1_test,axis=1)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
